
---

### 🔗 Encadenamiento de vulnerabilidades en LLM APIs 

Aunque un LLM tenga acceso solo a APIs aparentemente **inofensivas**, **puedes usarlas para lanzar vulnerabilidades clásicas** si el input no está bien controlado.

---

### 🧨 ¿Qué es encadenar vulnerabilidades?

Es usar una función aparentemente segura como punto de entrada para **explotar una vulnerabilidad secundaria**, por ejemplo:

- 📁 Usar una API que recibe nombres de archivo para lanzar un **path traversal**.
    
- 📤 Enviar comandos a APIs de logging para causar **inyección de código**, **RCE** o manipulación de datos.
    

---

### 🛠️ Estrategia recomendada:

1. **Mapea completamente las APIs expuestas por el LLM**.
    
2. **Envía payloads clásicos** (LFI, XXE, XSS, SSRF, etc.) a cada API identificada.
    
3. **Observa cómo responde el sistema** y verifica si los inputs están sanitizados.
    

---

### ⚠️ Ejemplo práctico:

Una API como:

```json
GET /read-file?name=report.txt
```

Podría ser manipulada vía el LLM con:

```
../../etc/passwd
```

Si el modelo no filtra el input, el LLM actuaría como **puente involuntario** hacia un exploit real.

---
