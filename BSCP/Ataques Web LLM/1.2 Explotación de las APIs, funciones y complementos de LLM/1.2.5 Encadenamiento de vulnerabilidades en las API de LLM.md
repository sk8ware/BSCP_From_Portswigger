
---

### ğŸ”— Encadenamiento de vulnerabilidades en LLM APIs 

Aunque un LLM tenga acceso solo a APIs aparentemente **inofensivas**, **puedes usarlas para lanzar vulnerabilidades clÃ¡sicas** si el input no estÃ¡ bien controlado.

---

### ğŸ§¨ Â¿QuÃ© es encadenar vulnerabilidades?

Es usar una funciÃ³n aparentemente segura como punto de entrada para **explotar una vulnerabilidad secundaria**, por ejemplo:

- ğŸ“ Usar una API que recibe nombres de archivo para lanzar un **path traversal**.
    
- ğŸ“¤ Enviar comandos a APIs de logging para causar **inyecciÃ³n de cÃ³digo**, **RCE** o manipulaciÃ³n de datos.
    

---

### ğŸ› ï¸ Estrategia recomendada:

1. **Mapea completamente las APIs expuestas por el LLM**.
    
2. **EnvÃ­a payloads clÃ¡sicos** (LFI, XXE, XSS, SSRF, etc.) a cada API identificada.
    
3. **Observa cÃ³mo responde el sistema** y verifica si los inputs estÃ¡n sanitizados.
    

---

### âš ï¸ Ejemplo prÃ¡ctico:

Una API como:

```json
GET /read-file?name=report.txt
```

PodrÃ­a ser manipulada vÃ­a el LLM con:

```
../../etc/passwd
```

Si el modelo no filtra el input, el LLM actuarÃ­a como **puente involuntario** hacia un exploit real.

---
