
---

### 🧬 Explotación de APIs, funciones y plugins en LLM 

Los LLMs muchas veces están **alojados por terceros** (como OpenAI, Anthropic, etc.), y pueden ser configurados para interactuar con funciones específicas de una web a través de **APIs locales**.

---

### 🔗 ¿Cómo funciona?

- El sitio web **describe sus APIs** al LLM para que este pueda ejecutarlas.
    
- El modelo no llama a funciones por sí mismo, pero **genera instrucciones que el sistema interpreta y convierte en acciones**.
    

---

### 🛠️ Ejemplo:

Un LLM de soporte al cliente podría tener acceso a:

- 📋 APIs de gestión de usuarios
    
- 📦 APIs de pedidos
    
- 🏷️ APIs de inventario
    

---

### ⚠️ Riesgo de explotación

Si un atacante **manipula el prompt**, podría lograr que el LLM:

- Llame a una API sensible sin intención original.
    
- Genere respuestas que el sistema convierte en acciones reales.
    
- 🔁 Actúe como puente para realizar acciones críticas sin controles adecuados.
    

---
