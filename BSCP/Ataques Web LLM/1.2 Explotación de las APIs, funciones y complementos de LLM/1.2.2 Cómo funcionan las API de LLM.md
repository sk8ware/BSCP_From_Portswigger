
---

###  驴C贸mo funcionan las APIs en LLMs? 

Cuando un LLM se integra con una API externa, puede seguir un flujo estructurado para que el cliente (sitio web o app) interprete y ejecute funciones solicitadas por el modelo.

---

### Л Flujo t铆pico de integraci贸n:

1.  El **usuario env铆a un prompt** al LLM.
    
2.  El LLM detecta que debe usarse una funci贸n y **genera un JSON** con los argumentos requeridos.
    
3.  El **cliente llama a la funci贸n/API** con esos argumentos.
    
4.  El cliente **recibe la respuesta** de la funci贸n.
    
5.  El cliente **reenv铆a la respuesta al LLM** como nuevo mensaje.
    
6.  El LLM usa la respuesta para completar la interacci贸n o **hacer otra llamada API interna**.
    
7.  Finalmente, el LLM **resume y muestra el resultado** al usuario.
    

---

### 锔 Riesgos de seguridad

- El LLM **act煤a como intermediario entre el usuario y APIs sensibles**.
    
- El usuario puede **no saber que se est谩n realizando llamadas reales** a funciones backend.
    
-  Se recomienda implementar una **etapa de confirmaci贸n** antes de ejecutar cualquier API cr铆tica.
    

---
