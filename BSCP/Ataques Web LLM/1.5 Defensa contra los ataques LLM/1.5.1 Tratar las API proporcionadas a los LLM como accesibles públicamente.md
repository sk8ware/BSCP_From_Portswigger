
---

### ğŸ” Tratar las APIs del LLM como si fueran pÃºblicas 

Dado que los usuarios pueden **inducir al LLM a llamar APIs** en su nombre, debes considerar cualquier API accesible por el LLM como **pÃºblicamente expuesta**.

---

### âš ï¸ Implicaciones de seguridad:

- El LLM **no debe ser responsable de aplicar restricciones o permisos**.
    
- Las APIs a las que el modelo tiene acceso deben estar **protegidas como si cualquier usuario pudiera accederlas directamente**.
    

---

### ğŸ›¡ï¸ Recomendaciones:

1. âœ… **AutenticaciÃ³n obligatoria** para cada llamada API.
    
2. ğŸ§± **Controles de acceso implementados en el backend real**, no solo en la lÃ³gica del LLM.
    
3. ğŸš« **No confiar en el modelo para filtrar o bloquear acciones sensibles.**
    
4. ğŸ” Controlar los privilegios ayuda a reducir:
    
    - Ataques por **prompt injection indirecto**.
        
    - Errores por **agencia excesiva**.
        

---

