
---

### 🔐 Tratar las APIs del LLM como si fueran públicas 

Dado que los usuarios pueden **inducir al LLM a llamar APIs** en su nombre, debes considerar cualquier API accesible por el LLM como **públicamente expuesta**.

---

### ⚠️ Implicaciones de seguridad:

- El LLM **no debe ser responsable de aplicar restricciones o permisos**.
    
- Las APIs a las que el modelo tiene acceso deben estar **protegidas como si cualquier usuario pudiera accederlas directamente**.
    

---

### 🛡️ Recomendaciones:

1. ✅ **Autenticación obligatoria** para cada llamada API.
    
2. 🧱 **Controles de acceso implementados en el backend real**, no solo en la lógica del LLM.
    
3. 🚫 **No confiar en el modelo para filtrar o bloquear acciones sensibles.**
    
4. 🔐 Controlar los privilegios ayuda a reducir:
    
    - Ataques por **prompt injection indirecto**.
        
    - Errores por **agencia excesiva**.
        

---

