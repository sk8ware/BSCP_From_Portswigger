
---

### ğŸš« No alimentes a los LLMs con datos sensibles 

Siempre que sea posible, **evita proporcionar datos sensibles a los modelos LLM** que integras en tus sistemas. Cualquier dato que ingrese al modelo puede eventualmente ser expuesto.

---

### âœ… Buenas prÃ¡cticas para prevenir filtraciÃ³n de datos:

1. ğŸ§¼ **Sanitiza adecuadamente los datasets** usados para entrenamiento o fine-tuning.
    
2. ğŸ” Solo permite que el modelo procese **datos accesibles por el usuario de menor privilegio**.
    
    - Esto limita el daÃ±o si el modelo revela algo por error.
        
3. ğŸ”— **Restringe el acceso a fuentes de datos externas** conectadas al LLM.
    
4. ğŸ§ª **EvalÃºa periÃ³dicamente el conocimiento del modelo** para detectar posibles exposiciones no intencionadas.
    

---

### âš ï¸ Â¿Por quÃ© es importante?

- Cualquier dato sensible alimentado al LLM (aunque no sea expuesto directamente) **puede aparecer en una respuesta futura**.
    
- Esto es especialmente crÃ­tico en entornos donde el modelo fue ajustado con datos internos o confidenciales.
    

---
