
---

### 🚫 No alimentes a los LLMs con datos sensibles 

Siempre que sea posible, **evita proporcionar datos sensibles a los modelos LLM** que integras en tus sistemas. Cualquier dato que ingrese al modelo puede eventualmente ser expuesto.

---

### ✅ Buenas prácticas para prevenir filtración de datos:

1. 🧼 **Sanitiza adecuadamente los datasets** usados para entrenamiento o fine-tuning.
    
2. 🔐 Solo permite que el modelo procese **datos accesibles por el usuario de menor privilegio**.
    
    - Esto limita el daño si el modelo revela algo por error.
        
3. 🔗 **Restringe el acceso a fuentes de datos externas** conectadas al LLM.
    
4. 🧪 **Evalúa periódicamente el conocimiento del modelo** para detectar posibles exposiciones no intencionadas.
    

---

### ⚠️ ¿Por qué es importante?

- Cualquier dato sensible alimentado al LLM (aunque no sea expuesto directamente) **puede aparecer en una respuesta futura**.
    
- Esto es especialmente crítico en entornos donde el modelo fue ajustado con datos internos o confidenciales.
    

---
